# development-notes
Конспекты по разработке ПО. Java, Kotlin, databases, CI\CD etc.

# Оглавление
* [Парадигмы программирования](#Парадигмы-программирования)
* Java
  * [ООП](#ооп)
    * Преимущества/отличие ООП от функционального программирования
    * [Отношения между классами](#отношения-между-классами)
  * Core
    * [Какой класс в Java не наследуется от Object](#Какой-класс-в-Java-не-наследуется-от-Object)
    * как так может случиться, что нельзя будет пробросить чекед ошибку наверх?
    * [Что такое литерал](#что-такое-литерал)
    * [Области памяти](#области-памяти)
    * Boxing, unboxing
    * equals, hashcode
    * [Перегрузка и переопределение методов](#перегрузка-и-переопределение-методов)
    * [Immutable класс](#immutable-класс)
    * [Абстрактные классы vs интерфейсы](#абстрактные-классы-vs-интерфейсы)
    * [Зачем нужен private конструктор](#зачем-нужен-private-конструктор)
    * [Рефлексия](#рефлексия)
    * Garbage collector
      * 3 типа прохода сборщика мусора, чем отличаются. (minor, major, full)
      * как работает GC
      * алгоритм сборки G1
      * алгоритм поиска мусора
  * [Stream API](#stream-api)
  * [Многопоточность](#многопоточность)
    * разница между синхронайзд в сигнатуре метода и синхронайзд для блока кода?
    * Как реализован дефолтный пул потоков? (BlokingQueue)
    * В чем заключается проблема ключевого слова synchronized?
    * локи
    * коллекции
    * синхронизаторы
    * атомики
    * volatile
    * тредпулы
  * Collections
    * как делается ГЕТ из хэшмапы? https://habr.com/ru/articles/421179/ 
    * как сделать чтобы мы могли положить в хэшмапу но НЕ могли достать?
    * [Arraylist](#arraylist)
    * [LinkedList](#linkedlist)
    * [HashMap](#hashmap)
    * [LinkedHashMap](#linkedhashmap)
  * как распределяются потоки в джаве и ос - кто чем владеет? реальные? логические?
  * Загрузчики классов, какие бывают? Наши кастомные классы какими загрузчиками загружаются?
  * Пространства памяти в Java (метаспейс, хип, стек)
  * В каком соотношении разделяется память на хип и остальное? (80%/20%)
  * [Интерфейсы](#интерфейсы)
  * Что появилось в 8 джаве - стримы, лямбды, функциональные интрефейсы.
  * Из каких частей состоит JVM Generations?
  * В чем заключается преимущество сборки приложения в виде исполняемого jar-файла?
  * Какие принципы лежат в основе реактивного программирования? 
* Kotlin
  * Когда используется Nothing
  * lazy vs lateinit
* [GraphQL](#graphql)
* Spring
  * как работает спринг стартер?
  * как написать свой спринг-стартер?
  * @Conditional
  * Цикл жизни бина
  * Dependency injection
  * Способы заинжектить бин (конструктор, сеттер и тп). Когда применимы
  * SpringBoot
    * (автоконфигурация, как работает)
    * [Как написать свой SpringBootStarter](#как-написать-свой-springbootstarter)
  * Скоупы бинов
  * @PostConstruct, @Predestroy
  * Spring MVC
  * Spring Security
  * Spring Data Jpa
  * Spring AOP
  * Spring Cloud
  * В чем ключевое различие между Spring MVC и Spring Webflux? 
  * Для чего используются профили в спринге (Для конфигурирования (например для дев и тестового стенда))
  * В чём отличие спринга от спринг бут?
  * работа аннотаций
  * bean post processor
  * CGLib, dynamic proxy
    * [Можно ли запроксировать класс если он final](#Можно-ли-запроксировать-класс-если-он-final)
* DSL
* Hibernate
  * проблема N+1, решение
  * @Transactional
  * ORM identity - сначала сохраняется в БД ентити и там на уровне БД присваивается id
  * ORM sequentity - перед сохранением сущности идёт запрос в БД для запроса следующего id
  * Требования к Entity классу
* Database
  * [Реляционные БД](#реляционные-бд)
    * [Архитектура СУБД](#архитектура-субд)
    * [SQL](#sql)
    * Каким образом измерить производительность SQL-запросов?
    * ACID
    * primary и unique - в чём разница?
    * как сделать cross join - не используя join ?
    * почему могут не отработать индексы, если установлены
    * нужен составной индекс на фамилию, дату рождения, пол - какой будем создавать (какое первое поле и какое дальше). Какой тип у этого индекса выбрать - hash, btree и тп
    * есть индекс составной (а,b) a и b колонки. Кидаем запросы с поиском по колонкам [b,a] , [b,c], [a,c] - где отработает индекс а где нет
    * в бд случается deadlock - как избежать
    * разница между explain и explain analyze. Откуда берутся цифры в explain
    * SQL-инъекции
    * уровни изоляции транзакций
    * отличие MySQL, Posgtres, Oracle
    * Каким образом сохраняются данные в бд если вылезла проблема с железом (свет погас, сервак взорвался).
  * Нереляционные БД
  * примеры NoSQL БД
  * реляц и нереляц БД - в чём разница, плюсы/минусы?
  * SQL vs noSQL
  * способы масштабирования бд
  * 
* Security
  * [JWT](#jwt)
  * [Basic auth](#basic-auth)
  * Отличие кодирования от шифрования
  * Алгоритмы шифрования
    * AES 256
    * RSA
    * DSS
    * hashing algorithm (salt)
  * Разница между авторизацей и аутентификацией
  * Role-based access control (RBAC)
  * Attribute-based access control (ABAC)
  * [Уязвимости](#уязвимости)
    * [Использование алгоритма хеширования NONE](#использование-алгоритма-хеширования-none)
    * [Использование украденного токена с действительным сроком действия](#использование-украденного-токена-с-действительным-сроком-действия)
  * Атаки
    * Bruteforce
    * DDoS
    * Rainbow table attack (https://www.cyclonis.com/ru/rainbow-table-password-attack-what-is-it-and-how-do-you-protect-yourself-from-it/)
    * man-in-the-middle
    * CSRF (Cross-Site Request Forgery)
* DevOps
  * Docker
    * виртуалки vs докер - плюсы, минусы?
    * как зайти в докер контейнер и что-то исполнить?
    * Как устроен Докер образ внутри? Слоями, начиная с верхнеуровневых и заканчивая твоим приложением.
    * Почему слои идут в таком порядке? Потому что при обновлении образа твоего приложения нужно будет обновить только его дельту. Если бы образы шли в обратном порядке - при изменении в образе нижнего порядка (jar-ника) приходилось бы изменять и образы верхних порядков (ОС и тп)
    * разница между RUN и CMD (RUN - команды выполняющиеся на этапе сборки имеджа, CMD - что запустим на этапе старта контейнера)
    * разница между arg и env? arg - параметры при билде имеджа (например чтобы кастомизировать версию джавы), env - параметры при запуске уже контейнера
    * [Через что общаются контейнеры между собой](#Через-что-общаются-контейнеры-между-собой)
    * Docker сети и зачем они. Host, bridge, overlay и тп
    * Как написать DockerFile
    * устройство контейнера
  * Kubernetes
    * [Основные сущности k8s](#Основные-сущности-k8s)
    * почему k8s отказалось от поддержки докера?
    * разница между pod и deployment
* Message brokers
  * Kafka
    * партиционирование
    * топик
    * брокер
    * Если положили в 3 разных партиции 3 ивента, можно ли вычитать их в таком порядке, в котором положили? (вроде партиции друг с другом не согласуются в этом плане.)
    * Как обеспечить чтобы несколько событий упали в 1 партицию? (использовать 1 идентификатор для них, например ид клиента. Тогда ивенты со сквозным идентификатором равным ид клиента пойдут в 1 партицию.)
  * RabbitMQ
  * Разница между ними
* Интернет
  * [SOAP](#soap)
  * [HTTP](#http)
    * [TCP UDP](#tcp-udp)
    * [WebSocket](#websocket)
    * [Firebase Cloud Messaging](#firebase-cloud-messaging)
    * синхронный и асинхронный http. Как работает
  * [gRPC](#grpc)
* Nginx
* Patterns
  * Strategy
  * Decorator
  * Template method
  * Singleton
  * Special Case
  * Factory
  * Builder
  * MVC
  * Facade
  * Adapter
  * основная транзакция закончила работу, надо кинуть выписку счета, но сервис может быть недоступен. Че делать (outbox pattern)
  * Какую задачу решает шаблон проектирования Memento?
* Tests
  * Test-containers
  * Mockito
  * JUnit
* [Problem solving](#problem-solving)
* Алгоритмы
  * как вычисляется высота кр чёрн дерева? (log n, где n это кол-во узлов )
  * Подробнее про алгоритмы сортировки, которые используются в java в Arrays.sort. Как работает, как меняется в зависимости от чего.
  * [Сложность алгоритмов](#сложность-алгоритмов)
* Архитектура
  * Микросервисы
     * +\-
     * есть сервис 1, отправляет запросы в сервис 2 и тот не отвечает. Что делать. Если сделали circuit breaker, то как потом пускать трафик на сервис 2 - все сразу или по частям
     * переполняется пул коннектов к сервису. Что делать.
     * метрики, как появляются, что будешь добавлять в свой новый сервисы
     * сильно дофига коннектов к сервису, что делать. Виды стратегий распределения запросов в load balancerдавать (какое первое поле и какое дальше). Какой тип у этого индекса выбрать - hash, btree и тп 
  * Монолит
    * +\-
  * [Stateful vs Stateless](#stateful-vs-stateless)
  * [REST](#rest)
    * [Модель зрелости Ричардсона](#модель-зрелости-Ричардсона)
  * [Одноранговая архитектура](#одноранговая-архитектура)
* Что такое Pub/Sub парадигма? Приведите примеры реализации
* Linux основные команды
* Как отвечать на вопросы, которые не знаешь? https://www.youtube.com/watch?v=Beoh3tfgPEk
* Вопросы интервьюеру на собеседовании
  * Норма покрытия кода тестами?
  * Есть ли документация к написанному коду?
  * Локальное поднятие сервисов
  * Конвейер фичи от бизнеса до клиента


## Парадигмы программирования
Совокупность идей и понятий, определяющих подход к программированию.
1. **Императивная** - характерные последовательные команды (инструкции). Говорит КАК решать задачу (язык ассемблера)
   1. **Структурная.** Программа выступает в виде иерархической структуры блоков. Разработка ведётся пошагово, сверху вниз. Основные управляющие конструкции: последовательность, цикл, ветвление.
   2. [Объектно-ориентированная](#ооп)
   3. **Аспектно-ориентированная** предлагает разделять программу на модули по функциональности.
2. **Декларативная** - указывает ожидаемый результат, а не способ его получения (HTML, SQL)

### ООП
Представляет программу, как совокупность взаимодействующих объектов.
у ООП есть всего три базовых принципа:
1. **Полиморфизм** простыми словами, это когда у одного и того же интерфейса может быть много разных реализаций. Пример - любая ORM, которая может работать с разными базами (в том числе, существуют комбинации SQL и noSQL), но ты как разработчик используешь только интерфейс
2. **Наследование** - это возможность переопределять поля и методы классов в рамках дерева иерархии
3. **Инкапсуляция** - это способ защиты внутреннего АПИ, суть ее в том, что публичные методы - это внешнее АПИ, а непубличные - внутреннее. Она используется для того, чтобы скрыть от разработчика или пользователя детали реализации. Кроме того, ты можешь менять внутреннее апи как угодно, не трогая внешнее.
Пример:
метод getDatabaseRecords - непубличный, получает данные из базы некоторые записи
метод GetUsers  - публичный метод, возвращает список юзеров.
Публичный метод внутри себя обращается к непубличному, и это и есть инкапсуляция
мы можем поменять базу, не меняя интерфейс GetUsers, можем менять реализацию обоих методов и т.д.
при этом, если кто-то захочет отнаследоваться от нашего класса, ему придется пилить getDatabaseRecords самостоятельно

[вверх](#оглавление)
### Отношения между классами
**Композиция** - неоъемлемая часть (напр. цельная отвёртка - металлическая часть и ручка её неотъемлемые части, квартира в доме). Это связь имеет\принадлежит. Если уничтожить объект владелец, то его составные части тоже будут уничтожены.

**Агрегация** - связь часть-целое между равноправными объектами (напр. автомобиль и колёса). 

**Ассоциация** - независимое взаимодействие (напр. разработчик и компьютер). HAS-A-отношения. 

[вверх](#оглавление)
### Что такое литерал
литерал - это константа, известная на этапе компиляции. 
нарпимер, print("Hello"),  hello - это литерал, потому что он не связан ни с какой переменной

[вверх](#оглавление)
### Области памяти
**Metaspace** (до Java 8 PermGen) - хранит метаданные. PermGen был частью кучи до Java 8, metaspace вынесен из кучи. Metaspace позволил оптимизировать процесс очистки памяти. Теперь сборщик мусора автоматически удаляет из памяти ненужные классы, когда емкость, выделенная для хранения метаданных, достигает максимального значения.
Static сущности (классы, методы, блоки инициализации) хранятся в метаспейсе. Static блок инициализации выполняется во время загрузки классов в JVM. Поэтому к статическим методам и переменным можно обращаться до их объявления.

**Heap (куча)** - хранит объекты, JRE-классы. Объем кучи гораздо больше, чем стека, но доступ к ней дольше и память освобождается не сразу, а после работы Garbage collector-a. В куче сущности делятся на объекты нового и старого поколения. Объектами старого поколения считаются те, которые пережили хотя бы 1 проход GC.

**Stack (стек)** - хранит ссылки на объекты в куче, примитивы, локальные переменные (переменные запущенного метода). Работает по принципу LIFO (last in, first out). В стеке могут храниться локальные переменные нескольких методов, если они вызывают друг друга по цепочке. После выхода из метода блок этого метода с его локальными переменными удаляется. Стек - самая маленькая область памяти, но самая быстрая, т.к. стек локализован в памяти и данные из него могут быть загружены в кэш процессора для быстрого доступа.

[вверх](#оглавление)
## Перегрузка и переопределение методов
Перегрузка (overload) – это создание конструктора класса или метода с таким же названием, но разным составом параметров.
Это нужно, например, когда допускаются значения полей класса по умолчанию  и идёт вызов конструкторов класса по цепочке. При перегрузке сигнатура метода меняется (количество параметров, их тип), имя метода остаётся таким же.

Переопределение (override) - когда дочерний класс меняет реализацию родительского метода.

Переопределение и перегрузка методов в Java — важные части полиморфизма.

[Подробнее](https://habr.com/ru/companies/otus/articles/347900/)

[вверх](#оглавление)
## Immutable класс
 * final class (чтобы от него нельзя было наследоваться)
 * все поля final private (поля инициализируются при создании объекта и больше не меняются)
 * из методов доступа есть только геттеры 
 * геттеры возвращают копию объекта\поля
 * для полей-коллекций необходимо делать глубокие копии, чтобы гарантировать их неизменность

[вверх](#оглавление)
## Абстрактные классы vs интерфейсы
Абстрактный класс - описывает абстрактный объект, не только его поведение. Если класс содержит хотя бы 1 абстрактный метод - класс должен быть абстрактным. Но абстрактным может быть и класс без абстрактных методов. Абстрактный класс - концептуальный объект.

Интерфейс определяет только поведение. 

[вверх](#оглавление)
## Зачем нужен private конструктор
* Для создания утилитных классов со статическими методами, чтобы нельзя было создать инстанс такого класса.
* Для реализации паттерна Singleton. Чтобы гарантировать, что инстанс данного класса будет создан только 1 раз.

[вверх](#оглавление)
## Рефлексия
**Reflection** - механизм манипуляции объектами в обход стандартных механизмов в runtime (во время выполнения программы). С помощью рефлексии можно получить информацю о классах, интерфейсах, полях, методах в runtime, не зная их имён.
Рефлексия нарушает инкапсуляцию и работает немного дольше. 
Spring framework строится на рефлексии.

[вверх](#оглавление)
### Какой класс в Java не наследуется от Object
Все классы в Java наследуются от Object. Можно сказать, что сам Object не наследуется.

[вверх](#оглавление)
### Можно ли запроксировать класс если он final
Да, если через интерфейсы (JDK dynamic proxy), нет, если через классы-наследники (CGLib) https://habr.com/ru/post/347752/ А можно ли запроксировать final метод? Нет, так как его же надо будет оверрайднуть

[вверх](#оглавление)
### Реляционные БД
**Основные понятия**
Сущность - класс, хранящийся в БД, таблица.

Объект - экземпляр сущности.

Атрибут - столбец.

Кортеж - строка, набор атрибутов.

Домен - набор допустимых значений атрибута.

Идентификатор - атрибут с уникальным значением для этой таблицы.

[вверх](#оглавление)
### Архитектура СУБД

1. Ядро — процессы, сеть, память, файловая система и т.п.
2. Диспетчер данных — транзакции, кэш.
3. Диспетчер запросов — парсер запроса, оптимизатор, исполнитель
4. Набор инструментов для служебных операций — утилиты для резервного копирования, восстановления, мониторинга.

[вверх](#оглавление)
### SQL
**Structured Query Language** — это декларативный язык программирования (язык запросов), который используют для создания, 
обработки и хранения данных в реляционных базах данных.

[вверх](#оглавление)
### Через что общаются контейнеры между собой
технически - через bridge - это специальное сетевое устройство канального уровня, в линуксе оно эмулируется на уровне ядра, т.е. все докер контейнеры общаются друг с другом через виртуальную локальную сеть. Также, можно при старте контейнера передать флат --net=host, тогда контейнер будет использовать сеть хост системы вместо бриджа

[вверх](#оглавление)
### Основные сущности k8s
**Манифест Kubernetes** — yaml конфиг файл, который описывает желаемое состояние ресурсов в кластере Kubernetes

**Архитектура кластера Kubernetes**
![Frame 31 (1).png](..%2F..%2F..%2FAC3E2%7E1.STE%2FAppData%2FLocal%2FTemp%2F4%2FFrame%2031%20%281%29.png)

**Control Plane** (управляющий уровень) отвечает за управление состоянием кластера
1. **kube-api-server** - центр всех взаимодействий с кластером. Все команды пользователей и компонентов k8s идут через него. API для управления состояние кластера.
2. **kube-scheduler** - отвечает за распределение Подов, которые ещё не назначены на Воркер Ноды. Он анализирует ресурсы Нод и выбирает подходящие для запуска Подов, основываясь на критериях, таких как количество доступной памяти и процессорных ядер.
3. **kube-controller-manager** - управляет контроллерами, которые следят за состоянием объектов кластера (напр. за состоянием Подов). Все Контроллеры взаимодействуют с API-сервером, подписываясь на события, связанные с их ресурсами.
4. **etcd** - распределённое key-value хранилище, где сохраняется вся информация о состоянии кластера. В нём хранится полная конфигурация и текущее состояние Kubernetes. Весь кластер можно восстановить, имея резервную копию etcd.
**Data Plane** (уровень выполнения) обеспечивает работу приложений на воркер-нодах
1. **kubelet** - это агент на каждой Воркер Ноде (*), который отвечает за управление Подами. Он получает инструкции от API-сервера и следит за тем, чтобы Контейнеры в Подах запускались и корректно работали.
2. **kube-proxy** управляет сетевым трафиком внутри кластера. Он настраивает правила маршрутизации и сетевых подключений, что позволяет Подам взаимодействовать друг с другом и получать доступ к внешним сетям. Это ключевой компонент для реализации сервисов Kubernetes, обеспечивающий корректное направление трафика к нужным Подам.
3. **Runtime (среда выполнения контейнеров)** отвечает за непосредственное выполнение Контейнеров. Это может быть Docker (в старых версиях k8s), CRI-O, containerd или другая совместимая среда выполнения. Runtime взаимодействует с контейнерными Образами и запускает их на Воркер Нодах.

**Namespace** - пространство имён. Позволяет логически разделять и группировать ресурсы (например бэк и фронт, разные продуктовые команды). Аналог папки на компьютере.
Все операции по дефолту выполняются в неймспейсе default.

```kubectl get ns``` - просмотр неймспейсов
```kubectl create ns examples-dev2``` - создать неймспейс
```kubectl delete ns examples-dev2``` - удалить нс

Зачем использовать неймспейсы?
1. **Организация и управление** — разделение сред, команд и т.п.
2. **Управление доступом** — Неймспейсы позволяют настраивать права доступа. Например, разработка имеет доступ к тесту и прода, а QA только к тесту.
3. **Безопасность** — Kubernetes позволяет настраивать NetworkPolicy (не совсем из коробки), например, запретить сетевому трафику покидать определённый Неймспейс, это помогает ограничить доступ.

**Pod** - набор контейнеров. Pod переводится как стручок, стало быть семена в стручке — Контейнеры. Под — это минимальная единица, которой управляет Kubernetes.
Контейнеры в одном Поде могут обмениваться файлами через общий том (volume). Процессы Контейнеров при этом все также изолированы
Поды в одном Неймспейсе могут быть с разных Нод, но Контейнеры в одном Поде только на одной Ноде.

```kubectl -n namespace-name get pods``` - просмотре подов неймспейса. Флаг -n нужен для указания Неймспейса
```-o wide``` — на какой Ноде находится Pod
```-o yaml``` — позволяет получить YAML-манифест Пода
```--show-labels``` - добавляет к выводу лейблы пода
```kubectl describe pod -n namespace-name pod-name``` - даёт детализированную инфу о поде
```kubectl -n web-app-dev logs simple-web``` - просмотр логов пода, -f просмотр в реальном времени
```kubectl exec -it -n namespace-name pod/pod-name -c container-name -- sh``` - shell контейнера в поде. Для выхода exit.
```kubectl top pods -n namespace-name``` - мониторинг использования ресурсов подами

Контроллеры в Kubernetes помогают автоматизировать управление приложениями, поддерживая их в желаемом состоянии. Без них управление Подами было бы ручным и подверженным человеческим ошибкам.

**Deployment** - самый популярный контроллер в Kubernetes, он используется для управления Подами и для поддержания их в требуемом количестве.
Deployment не контролирует Поды, т.к. это контроллер контроллера ReplicaSet

**ReplicaSet** - контроллер k8s, который поддерживает количество реплик в соответствии со спекой.

**Разница между deployment и ReplicaSet**
Deployment наследует весь функционал ReplicaSet и добавляет к этому функционалу дополнительные возможности:

- Deployment создает ReplicaSet'ы и хранит историю релизов. В старых ReplicaSet'ах он просто ставит количество реплик 0
- Благодаря истории релизов, Deployment позволяет делать откаты
- ReplicaSet не поддерживает обновления, он только приводит количество Подов к желаемому состоянию
- Deployment поддерживает обновления и позволяет настраивать стратегии обновления

ReplicaSet контролирует количество Подов
Deployment контролирует ReplicaSet'ы
Deployment контролирует ReplicaSet, а ReplicaSet контролирует Pod через labels - selector

**RollingUpdate** - плавная стратегия обновления без простоя. Сначала создаются новые Поды с новой версией приложения, после их успешного запуска удаляются старые Поды.

**Service** - сущность, с помощью которой можно создать постоянный IP-адрес и доменное имя, которые не меняются, даже если меняются сами Поды. 
Так можно подключаться в Подам внутри кластера по имени или по IP или сделать Под доступным из внешнего мира.
Через имя сервиса можно обращаться к Подам в рамках одного неймспейса. Из другого неймспейса можно обращаться по полному имени:
namespace.service-name

Сервис распределяет трафик по своим Подам равномерно (round robin).
**ТИПЫ СЕРВИСОВ**
**ClusterIP** — тип Сервиса, который создает виртуальный IP-адрес внутри кластера. Это тип сервиса по умолчанию. Даёт доступ только внутри кластера.

**NodePort** - открывает доступ по порту (30000–32767) извне. То есть все обращения на этот порт на любой ноде будут направлять трафик в этот сервис и дальше в его поды.

**LoadBalancer** - для подключения из внешнего мира к приложению через стабильный IP. Это не работает из коробки, нужна реализация такого сервиса.

**DaemonSet** - для деплоя по одному Поду на Ноду кластера. Например, для сбора метрик с каждой ноды.

**Job** - контроллер, который запускает Pod для выполнения конкретной задачи, а затем завершает его работу.

**CronJob** - контроллер контроллера Job. CronJob запускает Job по расписанию, подобно cron в Linux.

**StatefulSet** - это контроллер для управления Подами, которым нужны следующие возможности:
- уникальные идентификаторы
- стабильные сетевые имена
- стабильное постоянное хранилище для каждого Пода

Примеры:
- Базы данных (MySQL, PostgreSQL, Cassandra)
- Кэш-системы (Redis, Zookeeper)
- Брокеры сообщений (RabbitMQ, Apache Kafka)
- Файловые системы и хранилища (Minio, Nexus)

**StatefulSet vs. Deployment**
- Deployment порождает ReplicaSet, который контролирует Поды
- StatefulSet напрямую управляет Подами, обеспечивая их порядок и идентичность

- Deployment не гарантирует порядок и уникальность Подов. Поды могут запускаться в любом порядке, их имена не сохраняются при пересоздании 
- StatefulSet гарантирует уникальные имена Подов и их запуск в строгом порядке (по порядковым номерам). Это важно для кластеризированных приложений

- В Deployment все Поды могут монтировать один и тот же PV (Persistent Volume), если он указан
- В StatefulSet каждый Под монтирует свой собственный PV, что важно для репликации данных в случае stateful-приложений (например, БД)

- Deployment перезапускает Поды в любом порядке при обновлениях или сбоях
- StatefulSet перезапускает Поды в строгом порядке (последовательно)

- Deployment имеет возможность гибко обновлять наше приложение (rolling updates), но не учитывает порядок Подов
- StatefulSet обновляет Поды строго последовательно, начиная с самого старшего, pod-2 -> pod-1 -> pod-0

- Deployment не обеспечивает постоянных сетевых идентификаторов для Подов
- StatefulSet назначает Подам постоянные DNS-имена, чтобы каждый Под можно было адресовать по имени. Для точечного доступа к конкретному Поду можно использовать Headless Service


[вверх](#оглавление)

### Stateful vs Stateless
**Stateful API** - сервер запоминает состояние клиента при нескольких запросах. Он хранит информацию о клиенте, такую как предпочтения пользователя, прошлые действия или другие данные, относящиеся к взаимодействию клиента с веб-службой.

Плюсы:
+ Персонализация - можно обеспечить персонализированный пользовательский опыт на основе прошлых взаимодействий клиента
+ Проще навигация - не нужно каждый раз проходить аутентификацию, чтобы перемещаться между разными частями веб-приложения

Минусы:
- Проблемы масштабируемости - хранение состояния клиента на сервере потребляет ресурсы и может стать узким местом при увеличении числа клиентов
- Сложность - управление состоянием клиента на сервере усложняет приложение и делает его более сложным в обслуживании и устранении неполадок

Пример: работа с файлами по FTP протоколу — каждое действие клиента регистрируется сервером в состояние и сохраняется на сервере

**Stateless API** - сервер не хранит информацию о состоянии клиента между запросами. Каждый запрос должен содержать всю необходимую информацию, чтобы сервер мог его обработать

Плюсы:
+ Масштабируемость - серверу не нужно хранить и управлять состоянием клиента, это освобождает ресурсы
+ Простота - не нужно управлять состоянием на сервере, проще обслуживать и устранять непладки

Минусы:
- Меньше персонализация, т.к. сервер не запоминает прошлые взаимодействия клиента
- Повышенная сложность на стороне клиента. Клиент должен управлять своим состоянием и включать всю необходимую информацию в каждый запрос

Пример: REST API

**Cookies в REST API**
Иногда RESTful API нужно минимальное управление состоянием, например, аутентификация пользователя, отслеживание сессии или персонализация. В этих случаях cookies могут использоваться для хранения минимального количества информации о состоянии на стороне клиента, позволяя серверу извлекать эту информацию при необходимости.
Использование cookies может помочь поддерживать минимальное количество состояния на стороне клиента и при этом придерживаться принципа отсутствия состояния в RESTful API.

[вверх](#оглавление)

### REST
**REST** - архитектурный стиль взаимодействия компонентов в сети. Он обеспечивает простой, стандартизированный и масштабируемый способ создания веб-сервисов. Его простота и использование знакомых методов HTTP и встроенных механизмов кеширования делают его легким для изучения и внедрения разработчиками.
Преимущества:
+ Простота
+ Гибкость
+ Производительность
+ Надёжность

**Концепции REST**
1. Клиент-серверная архитектура (разделение зон ответственности).
   + можно вносить изменения только в нужно компоненте (сервер\клиент\бд)
   + масштабируемость (добавить клиента, реплику бд, инстанс сервера)
2. Отсутствие состояния (stateless)
  + позволяет масштабировать сервисы (нет проблем с определением на каком инстансе данные конкретного клиента)
  + повышает отказоустойчивость (если 1 сервис упал, трафик уйдёт на другой, данные не потеряются, т.к. упавший сервис их не хранил)
3. Кеширование — это техника, используемая для хранения и повторного использования результатов предыдущих вычислений или запросов в веб-интерфейсах. Она позволяет значительно повысить производительность и скорость отклика веб-приложений. Можно кешировать на стороне клиента, на стороне сервера, на стороне промежуточного сервера между клиентом и целевым сервером. 
Например, используют CDN для быстрой доставки контента в разных регионах.
   * кэш сервера (не ходить каждый раз в БД в течение актуальности данных в кэше)
   * кэш клиента (у мобильного приложения\браузера). При долгом ожидании ответа от сервера (тяжёлый запрос) можно кэшировать на клиенте и у сервера уточнять только актуальны ли данные в кэше на клиенте.
Плюсы:
   + производительность
   + меньше нагрузка на сервер
   + лучше пользовательский опыт (меньше отклик)
Минусы:
   - согласованность данных (между кэшом и БД)
   - аннулирование кэша (срок жизни и обновление кэша - по времени, на основе событий, комбинированный подход)
   - ограничения на размер кэша
   - повышенная сложность разработки
4. HATEOAS - единообразие интерфейса (3 уровень зрелости API Ричардсона), т.е. API может возвращать не только данные по запросу, но и ссылки на другие действия\ресурсы.
Ограничения этой концепции:
   * идентификация ресурса - каждый ресурс должен иметь уникальный идентификатор (URL). Он отделяет ресурс от его представления (в HTML, XML, JSON)
   Пример: Интернет-магазин может иметь ресурс продукта, идентифицируемый URL "/products/123". Сервер может отправить информацию о продукте в JSON\XML и т.п., в зависимости от запроса клиента
   * манипулирование ресурсами через представление - когда клиент получает представление ресурса, включая его метаданные, он должен иметь достаточно информации, чтобы изменить или удалить ресурс
   Пример: при получении JSON-представление продукта, оно должно содержать все необходимые детали (название, цену, категорию и т.д.) и метаданные (URL ресурса), чтобы клиент мог обновить или удалить продукт, используя эту информацию
   * самоописательные сообщения - клиент-серверные сообщения должны содержать достаточно информации, чтобы описать, как оно должно быть обработано (тип содержимого - application/json, text/html)
   Пример: заголовок Content-type=application/json в запросе, код состояния (201 Created) в ответе
5. Слоистая архитектура - архитектура из множества компонентов (секьюрити сервер, балансировщик, прокси для кэширования и т.п.)
Преимущества концепции: компоненты знают только о своих соседях (можно добавлять, убирать, изменять звенья цепи)
6. Код по запросу (необязательное ограничение)
Например сервер может вернуть скрипт для исполнения на клиенте.

**Ресурс** - основа REST, при проектировании REST API вначале проектируют ресурсы, которые будут доступны по API и далее назначить URL-адреса им.
Виды ресурсов:
1. Объект
api.com/users/{user-id} - пример доступа к ресурсу
2. Коллекция - то, как выстроил сервер структуру своих ресурсов. Клиент не управляет этой структурой, а только пользуется.
api.com/users - условный каталог, где есть много ресурсов пользователей
3. Хранилище - инициатор структуры клиент, а не сервер. То есть клиент создаёт файл, его название, путь до него.
api.com/files
4. Контроллер - не изменяет ресурс, но выполняет какие-то действия
POST api.com/sms-send

Подходы к выбору структуры ресурсов:
1. Структура должна расширяться
Например: 
/customers/3/purchases для всех заказов клиента №3
/customers/3/purchases/35 для покупки 35 клиента №3
2. Разбиение ресурсов на отдельные коллекции
/customers/3
purchases/35 - тут в API должен быть параметр с идентификатором клиента

**REST CRUDL**
1. CREATE - для создания нового ресурса или добавления чего-либо в существующий ресурс
   * POST - подходит для создания ресурсов. Тогда в ответе придёт идентификатор созданного ресурса (заголовок Location) и тело (либо только метаданные о созданном ресурсе)
   * PUT - используется для создания ресурса, если клиент может предоставить id для этого ресурса (например, положить файл в хранилище с нужным ему id). По умолчанию идемпотентный, небезопасный, не кэшируется. Подходит для создания файлов в хранилище и т.п. Ответ без тела.
2. READ
  * GET - для получения данных о существующем ресурсе. По умолчанию обладает свойствами:
    * Идемпотентный (одинаковый ответ при одинаковом запросе)
    * безопасный (не меняет информацию на сервере)
    * кэшируемый - по умолчанию ответ от него кэшируется
  * HEAD - частичное чтение, возвращает ответ без тел (только заголовки и код статуса)
  * OPTIONS - возвращает доступные методы, которые сервер разрешает клиенту выполнять
3. UPDATE - для обновления существующего ресурса или замены его части
  * PUT - при изменении обновляются все данные, т.е. они все должны быть в запросе.
  * PATCH - возможно частичное изменение ресурса. По умолчанию не идемпотентный, не безопасный, не кэшиуемый. При работе с PATCH нужно знать идентификатор ресурса. В тело включаем только информацию, которую хотим изменить. В ответе будет статус, заголовки и тело.
4. DELETE - для удаления существующего ресурса
   * DELETE - удаляет ресурс типа объект. Идемпотентный (не полностью), не безопасный, не кешируемый. Тело запроса\ответа не обязательное.
5. LIST
  * GET + параметры


  


[вверх](#оглавление)

### Модель зрелости Ричардсона
**Richardson Maturity Model** (RMM) — модель, предложенная в 2008 году Леонардом Ричардсоном. Классифицирует веб-API на основе их соответствия четырём уровням модели, каждый более высокий уровень соответствует более полному соответствию дизайну REST.

Цель модели — определить, насколько хорошо архитектура веб-сервиса соответствует принципам REST.

**Уровни**
1. Уровень 0 — веб-API с единственным URI (обычно POST через HTTP), принимающим весь спектр операций, поддерживаемых сервисом. Ресурсы в этой форме не могут быть чётко определены.
2. Уровень 1 — вводит ресурсы и разрешает запросы к отдельным URI для отдельных действий вместо предоставления одной универсальной конечной точки (API). Ресурсы API по-прежнему обобщены, но можно определить область применения каждого из них.
3. Уровень 2 — система использует HTTP-глаголы, что обеспечивает дальнейшую специализацию ресурса и сужает функциональность каждой отдельной операции в рамках сервиса. Например, ресурс разделяется на два — один запрос предназначен только для получения данных (GET), другой — для изменения данных (POST).
4. Уровень 3 — вводит представление гипермедиа (HATEOAS) — элементы, встроенные в ответные сообщения ресурсов, которые могут устанавливать связь между отдельными объектами данных, возвращаемыми из API и передаваемыми в них. Например, запрос GET в систему бронирования отелей может возвращать количество доступных номеров вместе с гиперссылками, позволяющими клиенту забронировать определённые номера.

[вверх](#оглавление)

### Одноранговая архитектура
**P2P архитектура** - каждый узел (устройство) в сети выступают и в качестве клиентов, и в качестве серверов. Они совместно используют ресурсы без необходимости в централизованном сервере.
Системы P2P могут быть более устойчивыми и масштабируемыми по сравнению с архитектурой клиент-сервер.

Пример: BitTorrent, популярный протокол совместного использования файлов P2P, или криптовалютные платёжные системы

[вверх](#оглавление)

### SOAP
**SOAP** - протокол обмена сообщениям запрос-ответ
Сетевое взаимодействие через HTTP, HTTPS, SMTP, FTP и тп
Формат сообщений в XML
WSDL (язык описания веб-серверов) описывает API (не нужен доп язык программирования)
Независимый от языка и платформы

Общение между SOAP-клиент и SOAP-сервером происходит по протоколу HTTP, но поверх него идёт протокол SOAP с сообщением на WSDL

Плюсы
+ Строгая спецификация
+ Независимость от языка и платформы
+ Независимость от HTTP
+ Усиленная безопасность (WS-Security)
+ Надёжность (надёжная система обмена сообщениями)

Минусы
- Сложность внедрения
- Производительность
- Масштабируемость
- Ресурсоёмкость (расходы на мощности сервера)

Применение
- Фин операции
- API следует за юр. контрактом
- Устаревшие системы
- Когда данные объёмны и нужен жёсткий формат

[вверх](#оглавление)

### GraphQL
**GraphQL** — язык запросов к данным и одновременно среда для выполнения этих запросов. Создан как альтернатива традиционным REST API. Вместо фиксированных маршрутов с заранее заданными структурами ответа GraphQL позволяет клиенту самому указать, какие данные ему нужны и в каком виде.

Плюсы
+ Единая точка входа
+ Эффективность загрузки (запрашиваешь только нужную инфу)
+ Разнообразие платформ
+ Сильная система типов

Минусы
- Сложнее REST в реализации
- Более сложное кеширование
- Сложнее настроить безопасность из-за гибкости (ограничение доступа к данным неавторизованным пользователям)
- Влияние больших запросов на производительность

Сетевое взаимодействие
- Независим от транспортного уровня
- Формат сообщений - JSON, сообщения graphQL 

Типы операций
- Query - чтение данных
- Mutation - запись, изменение, удаление
- Subscription - подписка на изменения (асинхронные взаимодействия через websockets)

**Схема GraphQL (SDL)** - находится на каждом сервере этого типа, представляет собой инструкцию, которая позволяет клиентам понять, какие операции сервер может выполнить и какие типы данных он может обрабатывать.

Состав схемы:
- Описания типов объектов и полей, которые представляют данные, получаемые через API
- Базовые или корневые типы, определяющие группу операций, которые API может обрабатывать

Т.е. схема включает в себя описание структуры данных, доступных через API, и допустимых операций, которые могут быть выполнены через этот API.

Resolver или распознаватели — функция, которая возвращает данные для определённого поля. Эту функцию пишут разработчики и она извлекает данные из различных источников, включая REST API, базы данных и другие источники.
Благодаря резольверам можно гибко получать данные для запрашиваемых полей из разных API, БД или других источников.

Для graphQL всегда используется POST запрос HTTP.

В GraphQL обычно не используются HTTP-коды ответов. Успех или неудача запроса определяется наличием ошибок в объекте ответа.

Область применения:
- сложные и меняющиеся требования к данным
- несколько клиентских приложений
- сложные системы и микросервисы

[вверх](#оглавление)

### HTTP

**HTTP 1.0**
* поддерживает только GET запрос
* позволяет получать HTML-файл с сервера
* одно TCP соединение на 1 запрос-ответ (тройное рукопожатие перед открытием соединения и закрытие соединения после получения http-ответа)

**HTTP 1.1**
* новые методы: PUT, PATCH, HEAD, OPTIONS, DELETE
* одно TCP-соединение для последовательных HTTP запросов-ответов

**HTTP 2.0**
* одно TCP соединение для всех запросов, даже для параллельных
* параллельные потоки можно приоритизировать
* сжатие заголовков
* push to client (отправка клиенту данных без запроса от него)
* больше не текстовый протокол
* запрос делится на фреймы (фрейм заголовков, фрейм тела)

Почему до сих пор не везде HTTP 2.0?
* Устаревшие системы и инфраструктура (нет поддержки HTTP 2)
* Несовместимость технологий с HTTP 2
* Не везде целесообразно. Например, сайты с небольшим количеством ресурсов или минимальным взаимодействием клиент-сервер могут не увидеть значительных улучшений от нового протокола
* Приоритет других задач (переход на HTTP 2 не главный приоритет)

[вверх](#оглавление)

### TCP UDP
**Модель TCP/IP (Transmission Control Protocol/Internet Protocol)** — это набор протоколов (описание различных правил), которые управляют передачей информации в интернете между устройствами.

TCP/IP
1. Канальный уровень (Wi-Fi/Ethernet) - определяем как устройство подключено к интернету. Физическая возможность отправлять/получать данные по сети
2. Сетевой уровень (IP) - маршрутизация пакетов данных от одного устройства к другому
3. Транспортный уровень - отвечает за передачу данных. Используются протоколы TCP/UDP
   TCP - следит, чтобы данные были доставлены и за порядком передачи данных, работает медленно
   UDP - не следит за успешной доставкой данных и их последовательностью, работает быстро
4. Прикладной уровень - обеспечивает связь между приложениями пользователей и базовыми сетевыми протоколами. Определяет стандарты и протоколы, которые позвляют программам на любых устройствах взаимодействовать по сети.
Протоколы:
* HTTP - протокол передачи гипертекста (веб-страниц и изображений)
* FTP - для передачи файлов
* SMTP - отправка и получение эл. почты
* DNS - domain name system, для преобразования доменных имён в ip-адреса
* telnet - для удалённого входа в систему и доступа к сетевым устройствам
* SSH - для безопасного удалённого доступа к сетевым устройствам

Процесс выглядит так:
1. Когда устройство хочет отправить данные через интернет оно использует IP для маршрутизации данных к устройству назначения.
2. Протокол TCP используется для разделения данных на пакеты, присвоения заголовков пакетам (для указания места пакета в последовательности)
3. TCP отправляет пакеты через интернет
4. Пакеты собираются воедино с учётом заголовков из п.2
5. Обработка на прикладном уровне

Когда используются ТСР
В приложениях, которые требуют высокой надежности и последовательности данных, например:
* Веб-браузеры (HTTP/HTTPS),
* Передача файлов (FTP),
* Электронная почта (SMTP, POP3, IMAP),
* Защищенные сетевые соединения (SSH).

Когда используются UDP
В приложениях, где быстрота важнее надежности, например:
* Видео и аудио звонки,
* Игры с многими игроками,
* DNS (Domain Name System)

[вверх](#оглавление)
### WebSocket
**Веб-сокеты** это продвинутая технология, позволяющая открыть постоянное двунаправленное сетевое соединение (поверх TCP) между браузером пользователя и сервером. С помощью его API вы можете отправить сообщение на сервер и получить ответ без выполнения http запроса, причём этот процесс будет событийно-управляемым.

#### Как работают веб-сокеты?
Соединение между клиентом и сервером остается открытым, пока не будет остановлено одной из сторон или будет закрыто по таймауту. Для установления соединения между клиентом и сервером они производят “рукопожатие” (handshake). Установленное соединение остается открытым, а связь осуществляется с использованием одного и того же канала, пока соединение не будет прервано на стороне клиента или сервера.
+ Запросы и ответы приходят без задержек и сетевой нагрузки.
+ Подходит для маркетплейсов, бирж, игровых приложений, чатов, соцсетей, интернета вещей, push-уведомлений.
[Как работают WebSocket](https://habr.com/ru/companies/qiwi/articles/747604/)

[вверх](#оглавление)
### Firebase Cloud Messaging
**Firebase Cloud Messaging (FCM)** — это кроссплатформенное решение для обмена сообщениями, которое позволяет надежно и бесплатно их отправлять (например push-уведомления клиентам через приложение.

Взаимодействие с FCM возможно как напрямую через отправку по REST данных на ендпоинт FCM, так и через библиотеку
com.google.firebase:firebase-admin.
[FCM documentation](https://firebase.google.com/docs/cloud-messaging?hl=ru)

[вверх](#оглавление)
### gRPC
**gRPC** - протокол удалённого вызова процедур от Google (open source).
* Работает на HTTP 2.0
* Формат сообщений - JSON и protobuf (в приоритете)
* валидация через Proto схему

**Protobuf**
Плюсы
* бинарный формат более эффективный, использует сжатие
* строгая типизация
* высокая производительность
* двунаправленный стрим
* поддержка разных платформ

Минусы
* сложность в настройке и использовании
* версионность службы (внесение изменений в API требует тщательного управления версиями схемы protobuf)
* нечитаемый (в отличие JSON)
* нужно кодировать и декодировать данные
* обработка ошибок (использует свои коды ошибок и сообщения состояний)

Режимы запросов в gRPC:
1. Простой RPC (унарный) - синхронный запрос от клиента, 1 запрос - 1 ответ
2. Серверный поток RPC (Server Streaming RPC) - при подключении клиента сервер открывает поток и начинает отправлять сообщения
3. Клиентский поток RPC (ClientStreaming RPC) - клиент открывает поток и начинает посылать запросы на сервер
4. Двухсторонний потоковый RPC (BI-Directional Streaming RPC) - клиент инициирует соединение и между клиентом и сервером открываются 2 стрима. Могут передавать данные одновременно

Применение:
* для высокопроизводительных систем с высокой частотой запросов
* для взаимодействия между сервисами на разных языках программирования
* для API со сценариями двунаправленного потока данных
* для систем обработки потоков данных в реальном времени
* для сетей с низкой пропускной способностью (за счёт бинарного формата)

[вверх](#оглавление)
### Arraylist
Capacity по умолчанию = 10. При превышении лимита создаётся новый массив по формуле:
новый массив = старый массив * 1,5 + 1
+ Быстрый перебор, быстрый поиск по индексу
+ Элементы упорядочены по индексу
+ Медленное добавление в середину

[вверх](#оглавление)

### LinkedList
* Двусвязный список
* Общая скорость  меньше, чем у ArrayList
* Лучше для вставок в середину и  удалений из середины
* Реализует интерфейсы Queue и Dequeu

[вверх](#оглавление)
### HashMap
Хеш-таблица. Структура данных ключ-значение.

Содержит в себе:
* table = Entry[] со ссылками на списки значений
* loadFactor (дефолтно 0,75)
* size
* treshold - порог при достижении которого capacity мапы увеличивается в 2 раза. treshold = capacity*loadFactor
* capacity (дефолтно 16)

Содержит bucket (корзины) с элементами. Бакет хранит nodes (узлы). Дефолтно бакетов 16. Если в бакете > 2 узлов, то бакет = LinkedList.

Как происходит добавление элемента в hashMap:
* Вычисляется хеш-код ключа элемента
* По хеш-коду ключа определяется бакет, в который будет добавлен элемент. Номер определяется по остатку от деления хэшкода на количество ячеек. В более новых версиях Java с помощью бинарного сдвига
* Если бакет пустой - элемент просто добавляется
* Если бакет не пустой – элемент добавляется в LinkedList внутри бакета
  * Ключ добавляемого элемента сравнивается с ключами в LinkedList по хэшкодам
  * Если хэшкоды не равны – переход к следующему элементу
  * Если хэшкоды равны – ключи дополнительно сравниваются по equals()
  * Если ключи равны по equals() – перезаписывается value найденного ключа
  * Если ключи не равны по equals() – переход к следующему элементу
* Если ключ не найден в LinkedList – элемент добавляется в конец списка

HashMap:
* Не отсортирован, не уорядочен
* Поддерживает null ключ
* Объекты с null ключами всегда записываются в нулевую ячейку массива
* Ключ в хешмапе должен быть иммутабельным и уникальным
* Нет trimToSize как у ArrayList, то есть нет возможности уменьшить размер после его увеличения
* Ключи отсортированы по значению их хеш-кодов
* Быстрая вставка и поиск элементов

В лучшем случае (правильно реализован hashCode()) время доступа к элементу O(1), константное. При плохой реализации hashCode() могут возникать коллизии, когда все элементы например попадают в один бакет. Тогда получаем время доступа к элементу за линейное время, O(n). Для оптимизации, при достижении внутреннего LinkedList размера 8 (8 элементов попали в один бакет), он преобразовывается в красно-чёрное дерево с логарифмическим временем доступа O(log(n)).

[источник](https://habr.com/ru/articles/696184/#HashMap)

[вверх](#оглавление)
#### Отличие HashMap от IdentityHashMap
Класс IdentityHashMap является реализацией абстрактного класса AbstractMap. Его отличие от HashMap состоит в том, что 
при сравнении элементов используется сравнение ссылок, а не значений.

#### В HashMap 16 элементов, добавляем ещё один. Что произойдёт?
мапа увеличится в 2 раза, элементы перераспределятся по новым бакетам. Потому что бакет для элемента выбирается на 
основе хешкода элемента и капасити мапы. Капасити соответственно изменилась.

#### Когда HashMap начинает использовать красно-черное дерево?

[вверх](#оглавление)
#### LinkedHashMap
Наследутся от HashMap (наследует поля: table, loadFactor, threshold, size, entrySet и т.п.).

Содержит доп. поля:
- header - голова двусвязного списка. При инициализации указывает сам на себя.
- accessOrder — указывает порядок доступа к элементам.
 - true — по порядку последнего доступа
 - false - доступ в порядке вставки элементов.

Плюсы  и минусы:
- Менее производителен, чем HashMap
- add, contains, remove за константное время
- итерация за линейное время O(n) (как у HashMap)
- сохраняется порядок вставки элементов

[Источник](https://habr.com/ru/articles/129037/)

[вверх](#оглавление)
### Интерфейсы
#### Что будет если мы имплементим 2 интерфейса с дефолтными методами с одинаковой сигнатурой?
Будет конфликт. - Как решить конфликт? переопределить метод и в нём явно указать ИмяИнтерф.super.defaultMethod() либо переопределить своей реализацией.

#### Spring

[вверх](#оглавление)
### Как написать свой SpringBootStarter
1. Создать новый проект (не Spring и не SpringBoot проект)
2. Создать класс с автоконфигурацией AutoConfiguration
```
@Configuration
@ConditionalOnClass(CustomClass::class) // класс, при наличии которого автоконфигурирование сработает
@ConditionalOnProperty(prefix = "your.config", name = ["name"], havingValue = "true", matchIfMissing = false) // блок конфигураций в application.yml, при значении которого автоконфигурирование сработает
@EnableConfigurationProperties(CustomProperties::class) // java/kotlin представление блока настроек из application.yml
@AutoConfigureBefore(SomeClass::class) //класс(ы) перед которым должно будет произойти автоконфигурирование
@AutoConfigureAfter(AnotherClass::class) //класс(ы) после которого должно будет произойти автоконфигурирование
class CustomAutoConfiguration {
    @Bean
    @ConditionalOnMissingBean
    fun someBean(): BeanClass { *init bean* }
}
```
3. Добавить информацию об автоконфигурации в resources
   * до spring 6. Добавить в resources директорию META-INF файл spring.factories с таким сдержимым
```
org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.example.autoconfig.CustomAutoConfiguration
```
   * после spring 6. Добавить в resources директорию META-INF/spring файл org.springframework.boot.autoconfigure.AutoConfiguration.imports, в котором прописать путь до автоконфигурации (com.example.autoconfig.CustomAutoConfiguration)

Стартер готов. Чтобы использовать его в другом сервисе нужно положить его в maven central либо в локальный maven repository. Затем нужно добавить стартер в качестве зависимости в проект и прописать необходимый блок настроек в application.yml (тот который в @ConditionalOnProperty автоконфигурации).

[вверх](#оглавление)
### Stream API
Создание стрима:
 * из коллекции
```
List<String> strings = List.of("a", "b", "c");
Stream<String> stream = strings.stream();
```
 * через генератор (нужно задать Supplier)
```
// сгенерирует 3 случайных числа с плавающей точкой 
    Stream.generate(new Random()::nextFloat)
        .limit(3);
```
 * из примитивов
```
    IntStream.range(0, 3);           // 0, 1, 2
    LongStream.rangeClosed(0L, 3L);  // 0L, 1L, 2L, 3L
```
 * через билдер
```
Stream<Integer> builtStream = Stream.<Integer>builder()
        .add(1)
        .add(2)
        .add(3)
        .build();
```
Тут если не указать тип данных, то получим стрим Object и не будет осуществляться проверка типов элементов.

#### почему внешняя переменная в стримах должна быть эффективли файнал?
#### Как быстрее просуммировать числа от 1 до 100 - через стрим или через паралел стрим (паралел стрим требует больше ресурсов и для малых объемов данных дорого получается)
#### Дефолтные методы в интерфейсах это костыль или фича? - костыль, это рушит всё ООП. Но других вариантов для введения стримов не было. 

[вверх](#оглавление)
### Многопоточность
**Многопоточность** - свойство платформы\приложения, которое позволяет процессу состоять из нескольких параллельных потоков. 

[вверх](#оглавление)
## Problem solving
### ExceptionHandler для @Scheduled методов
Проблема: @ExceptionHandler не работает для @Scheduled из-за многопоточности.
Решение: Spring AOP
```
@Aspect
@Component
class ExceptionHandlerForScheduledTasks {
    companion object : KLogging()

    @Pointcut("execution(* com.foo.services.ScheduledService.*(..))")
    fun scheduled() {
    }

    @Around("scheduled()")
    fun handleNoDataFoundException(joinPoint: ProceedingJoinPoint) =
        runCatching { joinPoint.proceed() }
            .onFailure { logger.error { "NoDataFoundException exception, cause: ${it.message}" } }
}
```
Альтернативное решение: реализовать свой ErrorHandler. Минус в том, что кастомный ErrorHandler будет использоваться как для @Scheduled методов, так и для остальных. Но для всех задач кроме @Scheduled должен использоваться дефолтный ErrorHandler, поэтому это решение не подходит.

[вверх](#оглавление)
### Сложность алгоритмов
**Сложность алгоритма или O(n)** - как влияет объём входных данных на время работы или расходуемую память.

[вверх](#оглавление)
## JWT
Предназначение JWT - проверка подлинности источника данных. При этом стоит понимать, что токен кодируется и подписывается, но не шифруется. Поэтому передавать в нём конфиденциальную информацию не стоит.
Создание JSON Web-Token:
1. Заголовок
```
{
  "typ": "JWT", \\ тип токена
  "alg": "HS256" \\ алгоритм хеширования. None - если токен не подписан
}
```
2. Полезная нагрузка (payload) - хранится информация о пользователе, которую сервер аутентификации передает серверу приложения.
Стандартные необязательные поля:
 * exp – срок окончания действия токена;
 * nbf – время начала действия токена;
 * sub – уникальный идентификатор пользователя.
Помимо стандартных ключей, можно передавать любые данные в виде пар key-value
Большой размер JWT может сказаться на производительности сервиса.
3. Подпись - вычисляется на основе его заголовка и полезной нагрузки по следующей схеме
```
data = base64urlEncode(header) + "." + base64urlEncode(payload) \\ Заголовок и полезная нагрузка по отдельности кодируются с помощью алгоритма Base64URL, а затем соединяются через точку
hashedData = hash(data, secret) \\ затем закодированные данные хешируется с использованием секретного ключа (secret)
signature = base64urlEncode(hashedData) \\ Хешированные данные снова пропускаются через Base64URL для получения подписи
```
4. Cборка JWT. На основании данных из п1-3 собираем веб-токен по схеме
```
header.payload.signature
```
Заголовок и полезная нагрузка предварительно кодируются в Base64URL, а подпись уже в правильном формате.

5. Верификация JWT. В примере выше использовалось хеширование с секретным ключом по алгоритму HS256. Изначально этот ключ известен только серверу аутентификации. Сервер приложения получает его при настройке процесса проверки подлинности.

Когда пользователь отправляет запрос с прикрепленным к нему JWT, приложение может самостоятельно произвести хеширование данных и сравнить результат с полученной подписью. Если строки совпадают, значит вызов поступил из подтвержденного источника и может быть выполнен безопасно.

![Схема авторизации через JWT](/jwt.png)

[Первоистичник](https://proglib.io/p/jwt-for-dummies)

[вверх](#оглавление)
## Basic auth
Базовая авторизация работает путем отправки имени пользователя и пароля в HTTP-заголовке 
```
Authorization: Basic :
```
Имя пользователя и пароль закодированы с использованием Base64. Например, если имя пользователя - “user”, а пароль - “password”, то закодированный заголовок будет выглядеть следующим образом:
```
Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=
```

[вверх](#оглавление)

## Уязвимости
### Использование алгоритма хеширования NONE
Подобная атака происходит, когда злоумышленник изменяет JWT, а также меняет алгоритм хеширования (поле “alg”), чтобы указать через ключевое слово none, что целостность токена уже проверена. Некоторые библиотеки рассматривали токены, подписанные с помощью алгоритма none, как действительный токен с проверенной подписью, поэтому злоумышленник мог изменить полезную нагрузку (payload) токена, и приложение доверяло бы токену.

Для предотвращения атаки необходимо использовать библиотеку JWT, которая не подвержена данной уязвимости. Также во время проверки валидности токена необходимо явно запросить использование ожидаемого алгоритма.

### Использование украденного токена с действительным сроком действия
Поскольку токен становится недействительным только после истечения срока его действия, у пользователя нет встроенной функции, позволяющей явно отменить действие токена. Таким образом, в случае кражи пользователь не может сам отозвать токен и затем заблокировать атакующего.

Одним из способов защиты является внедрение черного списка токенов, который будет пригоден для имитации функции «выход из системы», существующей в традиционной системе сеансов.

В черном списке будет храниться сборник (в кодировке SHA-256 в HEX) токена с датой аннулирования, которая должна превышать срок действия выданного токена.

Когда пользователь хочет «выйти», он вызывает специальную службу, которая добавляет предоставленный токен пользователя в черный список, что приводит к немедленному аннулированию токена для дальнейшего использования в приложении.

[вверх](#оглавление)
